{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15dcc817",
   "metadata": {},
   "source": [
    "# Project: Real-Time Communication system powered by AI for specially abled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9565ed",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f28d7",
   "metadata": {},
   "source": [
    "# Import The Required Model Building Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb6b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imagedatagenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe5707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training datagen\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df2a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing datagen\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae30b5",
   "metadata": {},
   "source": [
    "# IMPORTING tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9037b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99e807",
   "metadata": {},
   "source": [
    "# Initialize The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca064ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ef1dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #to view graph in colab itself\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7862917",
   "metadata": {},
   "source": [
    "# Applying ImageDataGenerator to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "136f9249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r\"C:\\Users\\G.G. SUNDER\\Dataset\\training_set\",target_size=(64,64),batch_size=200,\n",
    "                                          class_mode='categorical',color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0e7e5",
   "metadata": {},
   "source": [
    "# Applying ImageDataGenerator to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7deef6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory(r\"C:\\Users\\G.G. SUNDER\\Dataset\\test_set\",target_size=(64,64),batch_size=200,\n",
    "                                          class_mode='categorical',color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abf7f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=len(x_train)\n",
    "b=len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb5eab",
   "metadata": {},
   "source": [
    "# Length of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f5d58f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f78fe",
   "metadata": {},
   "source": [
    "# Length of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c6e0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865dfc8",
   "metadata": {},
   "source": [
    "# Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4809f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55329396",
   "metadata": {},
   "source": [
    "# Add The Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e9318cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,1),activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef32b2",
   "metadata": {},
   "source": [
    "# Add Pooling Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a02b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a5e0f",
   "metadata": {},
   "source": [
    "# Add The Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be1da832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc05720a",
   "metadata": {},
   "source": [
    "# Adding The Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c99fc3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st hidden layer\n",
    "model.add(Dense(units=512,activation='relu'))\n",
    "#2nd hidden layer\n",
    "model.add(Dense(units=261,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e936ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "model.add(Dense(units=9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3c7b0",
   "metadata": {},
   "source": [
    "# Compile The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "546e6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1741b04",
   "metadata": {},
   "source": [
    "# Fit The Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "925cac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GG77DA~1.SUN\\AppData\\Local\\Temp/ipykernel_25400/234118701.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 70s 840ms/step - loss: 0.5017 - accuracy: 0.8386 - val_loss: 0.1866 - val_accuracy: 0.9702\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 64s 810ms/step - loss: 0.0576 - accuracy: 0.9828 - val_loss: 0.1900 - val_accuracy: 0.9760\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 63s 789ms/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.1994 - val_accuracy: 0.9773\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 63s 796ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.2027 - val_accuracy: 0.9764\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 63s 790ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.1526 - val_accuracy: 0.9782\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 63s 797ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.2039 - val_accuracy: 0.9778\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 63s 798ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.2557 - val_accuracy: 0.9760\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 66s 829ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.1485 - val_accuracy: 0.9791\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 62s 786ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.1991 - val_accuracy: 0.9796\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 64s 802ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2506 - val_accuracy: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b4b46976a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e032843",
   "metadata": {},
   "source": [
    "# Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "133c1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aslpng2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d479c1b1",
   "metadata": {},
   "source": [
    "# Import The Packages And Load The Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fea5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bc416fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model=load_model('aslpng2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8ffc60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=500x400 at 0x1B4B73EE340>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img(r\"C:\\Users\\G.G. SUNDER\\Dataset\\test_set\\A\\54.png\",target_size=(400,500))\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
