{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88b217d",
   "metadata": {},
   "source": [
    "# Import The Required Model Building Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f2e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imagedatagenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#training datagen\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "#testing datagen\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b152d2",
   "metadata": {},
   "source": [
    "# IMPORTING tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b0db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5688e3b7",
   "metadata": {},
   "source": [
    "# Initialize The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882b5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71283e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #to view graph in colab itself\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c49c0",
   "metadata": {},
   "source": [
    "# Applying ImageDataGenerator to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d962ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15750 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r\"C:\\Users\\manoj\\Downloads\\conversation engine for deaf and dumb\\Dataset\\training_set\",target_size=(64,64), batch_size=300,\n",
    "                                          class_mode='categorical', color_mode = \"grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4258c2d9",
   "metadata": {},
   "source": [
    "# Applying ImageDataGenerator to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f932fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2248 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    " x_test = test_datagen.flow_from_directory(r\"C:\\Users\\manoj\\Downloads\\conversation engine for deaf and dumb\\Dataset\\test_set\",target_size=(64,64), batch_size=300,\n",
    "                                          class_mode='categorical', color_mode = \"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a98e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=len(x_train)\n",
    "b=len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a670ff",
   "metadata": {},
   "source": [
    "# Length of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4edf81d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baca58e",
   "metadata": {},
   "source": [
    "# Length of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bceeaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e4ed2",
   "metadata": {},
   "source": [
    "# Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a6bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf1a1a",
   "metadata": {},
   "source": [
    "# Add The Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d309117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,1),activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9ce8d",
   "metadata": {},
   "source": [
    "# Add Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b968ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a70b04",
   "metadata": {},
   "source": [
    "# Add The Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820f795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55585315",
   "metadata": {},
   "source": [
    "# Adding The Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54291c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st hidden layer\n",
    "model.add(Dense(units=512,activation='relu'))\n",
    "#2nd hidden layer\n",
    "model.add(Dense(units=261,activation='relu'))\n",
    "#output layer\n",
    "model.add(Dense(units=9,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a671d",
   "metadata": {},
   "source": [
    "# Compile The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4bdd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec1264",
   "metadata": {},
   "source": [
    "# Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4531bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manoj\\AppData\\Local\\Temp\\ipykernel_20200\\234118701.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - 44s 809ms/step - loss: 0.4233 - accuracy: 0.8552 - val_loss: 0.2601 - val_accuracy: 0.9359\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 39s 727ms/step - loss: 0.0431 - accuracy: 0.9888 - val_loss: 0.2324 - val_accuracy: 0.9742\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 38s 722ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.2089 - val_accuracy: 0.9778\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 41s 782ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.2633 - val_accuracy: 0.9773\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 42s 790ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.2343 - val_accuracy: 0.9795\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 38s 718ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.3209 - val_accuracy: 0.9778\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 42s 782ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.3734 - val_accuracy: 0.9715\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 36s 676ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.3022 - val_accuracy: 0.9778\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 34s 636ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.2250 - val_accuracy: 0.9813\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 33s 626ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.2532 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15861072d60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1ec78",
   "metadata": {},
   "source": [
    "# Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8175e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aslpng2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49373b78",
   "metadata": {},
   "source": [
    "# Import The Packages And Load The Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "def59edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f1479eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model=load_model('aslpng2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cee2ec54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=500x400 at 0x15800367250>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img('10.png',target_size=(400,500))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34165974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
